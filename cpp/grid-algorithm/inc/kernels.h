#include <cuda_runtime.h>
#include <curand_kernel.h>

#ifndef KERNELS_H
#define KERNELS_H

__global__ void setup_kernel(curandState *state)
{
  /*
  Initialize the random state independently for each thread.

  In CUDA programming, each thread has its own RNG state, which determines the
  sequence of random numbers generated by that thread. By initializing the RNG
  state, we ensure that each thread starts with a distinct and independent
  sequence of random numbers.
  */
    int id = threadIdx.x + blockIdx.x * blockDim.x;
    curand_init(42, id, 0, &state[id]);
}

__global__ void generate_normal_kernel(curandState *state,
                                unsigned int n,
                                float mu,
                                float sigma,
                                float *result)
{
  /*
  Generate random variates out of a normal distribution. 

  Arguments:
    n: the number of variates to generate.
    mu: the mean of the normal distribution.
    sigma: the standard deviation of the normal distribution.
    result: the array where the random variates will be stored.
  */
  int index = threadIdx.x + blockIdx.x * blockDim.x;
  int stride = blockDim.x * gridDim.x;

  float rv;

  /* Generate pseudo-random normals */
  for(int i = index; i < n; i += stride) {
    /* Copy state to local memory for efficiency */
    curandState localState = state[index];

    rv = curand_normal(&localState);
    result[i] = mu + sigma * rv;
  }
}

__global__ void linspaceKernel(float *array, int size, float start, float end)
{
  /*
  Create a linearly spaced array on the device.

  array: output array
  n: length of array
  start: start of range (included)
  end: end of range (included)
  */
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        array[idx] = start + idx * (end - start) / (size - 1);
    }
}


__global__ void create3dGridKernel(float *vecX, float *vecY, float *vecZ,
                                   float *gridX, float *gridY, float *gridZ,
                                   int vecXYSize, int vecZSize)
{
  /*
  Create the outer product of three vectors on the device.

  For the purpose of this project we assume that both XY vectors are the same
  size and only Z differs.

  Arguments:
    vecX: the first vector
    vecY: the second vector
    vecZ: the third vector
    gridX: the grid of the first vector to be filled
    gridY: the grid of the second vector to be filled
    gridZ: the grid of the third vector to be filled
    vecXYSize: the size of the vectors vecX and vecY
    vecZSize: the size of the vector vecZ
  */
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int ii = blockIdx.y * blockDim.y + threadIdx.y;
  int iii = blockIdx.z * blockDim.z + threadIdx.z;

  int idx = i * vecXYSize * vecZSize + ii * vecZSize + iii;

  if (i < vecXYSize && ii < vecXYSize && iii < vecZSize) {
    gridX[idx] = vecX[i];
    gridY[idx] = vecY[ii];
    gridZ[idx] = vecZ[iii];
  }
}


__device__ float normalPdf(float x, float mu, float sigma) {
  /*
  Calculate the PDF of a normal distribution on the device at some location x.

  Arguments:
    x: value
    mu: mean
    sigma: standard deviation
  */
  return exp(-0.5f * pow((x - mu) / sigma, 2.0f)) / (sigma * sqrt(2.0f * M_PI));
}


__global__ void computeDensitiesKernel(float *densities, float *gridX,
                                       float *gridY, float *gridZ, int gridSize)
{
  /* Compute the densities on the device.

  At this point we have three vectors that represent our 3d grid, so we just
  need to iterate over the arrays to get the densities for each pair of mu,
  sigma, over the observations (x).

  Arguments:
    densities: the array where we will store the computed densities.
    gridX: the array of values for mu as an outer product `mu x sigma x obs`
    gridY: the array of values for sigma as an outer product `mu x sigma x obs`
    gridZ: the array of values for the observations as an outer product
    gridSize: the size of all above arrays (101x101x50)
  */


  int i = blockIdx.x * blockDim.x + threadIdx.x;

  if (i < gridSize) {
    float x = gridZ[i];
    float sigma = gridY[i];
    float mu = gridX[i];
    densities[i] = normalPdf(x, mu, sigma);
  }
}


__global__ void computeLikesKernel(double *likes, double **likesMatrix, 
                                   int rows, int cols)
{
  /* Compute the likelihoods function on the device.

  1   2   3    4    5    6    7    8    9    10
  |___|   |____|    |____|    |____|    |_____|
    |        |        |          |         |
    2       12        30        56        90
    |________|        |__________|         |
         |                   |             |
         24               1680             |
         |___________________|             |
                  |                        |
                  40320                   90
                  |________________________|
                               |
                            3628800
  The simplest example is: in each iteration, group the elements in the array in
  pairs and compute their product so the max number of iterations will be
  log2(N).

  However, the final algorithm is a bit more elaborated as we are passing a
  matrix of 10201x50 elements (101*101x50) and the product is computed over rows
  which are the densities for each of the 50 observations.

       row 0              row 1
  --------------    ----------------
  1   2   3    4    5    6    7    8
  |___|   |____|    |____|    |____|
    |        |        |          |
    2       12        30        56
    |________|        |__________|
        |                   |
        24               1680
      output[0]         output[1]

  Arguments:
    likes: the array where will store the likelihood.
    likesMatrix: the matrix over which the reduction will be computed.
    rows: the number of rows in the matrix (10201).
    cols: the number of columns in the matrix (50).
  */
  int idx = blockIdx.x * blockDim.x + threadIdx.x;

  // Use a parallel reduction to calculate the product
  for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {
    if (idx < stride && idx + stride < cols) {
      for (int i = 0; i < rows; i++) {
        likesMatrix[i][idx] *= likesMatrix[i][idx + stride];
      }
    }
    __syncthreads();
  }

  // Store the result in the outcome
  if (idx == 0) {
    for (int i = 0; i < rows; i++) {
      likes[i] = likesMatrix[i][0];
    }
  }
}


__global__ void marginalizeKernel(double *marginal, double **posterior, 
                                  int rows, int cols, int axis)
{
  /*
  Compute the sum over rows or columns of a given matrix.

  TODO: This function seems to be a more general approach of above, so a
  refactor of both can be done

  Arguments:
    marginal: the array where the sum will be stored (101)
    posterior: the matrix to compute the sum for.
    rows: the number of rows of the matrix (101)
    cols: the number of columns of the matrix (101)
    axis: the axis number to perform the sum over. `axis=0` will represent the
    sum over rows, whereas `axis=1` will represent the sum over columns. 
  */

  int idx = blockIdx.x * blockDim.x + threadIdx.x;

  int outerRef, innerRef;
  if (axis == 0) {
    outerRef = rows;
    innerRef = cols;
  } else {
    outerRef = cols;
    innerRef = rows;
  }

  for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {
    if (idx < stride && idx + stride < outerRef) {
      for (int i = 0; i < innerRef; i++) {
        if (axis == 0) {
          posterior[idx][i] += posterior[idx + stride][i];
        } else {
          posterior[i][idx] += posterior[i][idx + stride];
        }
      }
    }
    __syncthreads();
  }

  if (idx == 0) {
    for (int i = 0; i < rows; i++) {
      if (axis == 0) {
        marginal[i] = posterior[0][i];
      }else{
        marginal[i] = posterior[i][0];
      }
    }
  }
}

#endif