#include <iostream>
#include <math.h>  // C std library
#include <curand.h>
#include <curand_kernel.h>


// this is a macro
#define CUDA_CALL(x) do { if((x) != cudaSuccess) { \
    printf("Error at %s:%d\n",__FILE__,__LINE__); \
    return EXIT_FAILURE;}} while(0)

/*
Sources:
https://developer.nvidia.com/blog/efficient-cuda-debugging-memory-initialization-and-thread-synchronization-with-nvidia-compute-sanitizer/

https://docs.nvidia.com/cuda/curand/group__DEVICE.html

https://chat.openai.com/c/ba212caf-491f-4dfd-ac4f-ce2132672561

TODO: Move them to a note on obsidian once we are done along with the learnings
*/

__global__ void setup_kernel(curandState *state)
{
  /*
  In CUDA programming, each thread has its own RNG state, which determines the
  sequence of random numbers generated by that thread. By initializing the RNG 
  state, we ensure that each thread starts with a distinct and independent 
  sequence of random numbers.
  */
    int id = threadIdx.x + blockIdx.x * blockDim.x;
    curand_init(42, id, 0, &state[id]);
}

__global__ void generate_normal_kernel(curandState *state,
                                unsigned int n,
                                float *result)
{
    /* 
    In this function we will be generating radom variates with curand_normal
    using the states defined in `setup_kernel`.
    */
    int index = threadIdx.x + blockIdx.x * blockDim.x;
    int stride = blockDim.x * gridDim.x;
    float mu = 0.0f;
    float sigma = 1.0f;
    float rv;
    
    /* Generate pseudo-random normals */
    for(int i = index; i < n; i += stride) {
      /* Copy state to local memory for efficiency */
      curandState localState = state[index];

      rv = curand_normal(&localState);
      result[i] = mu + sigma * rv;

      /* Copy state back to global memory */
      state[i] = localState;
    }
}


int main(void)
{
  const unsigned int threadsPerBlock = 64;
  const unsigned int blockCount = 64;
  const unsigned int totalThreads = threadsPerBlock * blockCount;  // 4096

  unsigned int numElements = 50;
  curandState *devStates;
  float *devResults, *hostRVs;


  /* MEMORY ALLOCATION */
  // TODO: change this to cudaMallocManaged once is working

  /* Allocate space for results on host */
  hostRVs = (float *)calloc(totalThreads, sizeof(float));

  /* Allocate space for prng states on device */
  CUDA_CALL(
    cudaMalloc(&devStates, totalThreads *sizeof(curandState))
  );

  /* Allocate space for results on device */
  CUDA_CALL(cudaMalloc(&devResults, totalThreads *
            sizeof(float)));


  /* Set results to 0 */
  CUDA_CALL(cudaMemset(devResults, 0, totalThreads *
            sizeof(float)));

  setup_kernel<<<blockCount, threadsPerBlock>>>(devStates);

  generate_normal_kernel<<<blockCount, threadsPerBlock>>>(
    devStates, numElements, devResults
  );

  cudaDeviceSynchronize();

  /* Copy device memory to host */
  CUDA_CALL(cudaMemcpy(hostRVs, devResults, totalThreads *
      sizeof(float), cudaMemcpyDeviceToHost));

  unsigned int count = 0;
  unsigned int withinOneSD = 0;
  for (int i = 0; i < numElements; i++) {
    std::cout << hostRVs[i] << std::endl;
    if (hostRVs != 0)
      count++;
    if (hostRVs[i] > -1.0 && hostRVs[i] < 1.0) {
      withinOneSD++;
    }
  }

  std::cout << "RVs generated: " << count << std::endl;
  std::cout << "Within one SD: " << (float)withinOneSD / count << std::endl;

  /* Cleanup */
  CUDA_CALL(cudaFree(devStates));
  CUDA_CALL(cudaFree(devResults));
  free(hostRVs);

  return 0;
}